{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\T-Gamer\\\\Documents\\\\SideDrive\\\\UFMA\\\\2022.1\\\\Topicos Especiais (NLP)\\\\Exercicios\\\\Trabalho Final\\\\Implementação\\\\source'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, nltk\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\T-Gamer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset_folder = \"../resources/datasets/TwitterAirlines\"\n",
    "dataset = pd.read_csv(f\"{dataset_folder}/Tweets.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\"airline_sentiment\", \"airline_sentiment_confidence\", \"text\"]\n",
    "dataset_clean = dataset.iloc[ : , [column in columns_to_keep for column in dataset.columns]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_clean.to_csv(f\"{dataset_folder}/TweetsDroppedCols.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_ats_hashtags_and_links(text:str) -> str :\n",
    "    gross_tokenlist = text.split()\n",
    "    text = \"\"\n",
    "    for gross_token in gross_tokenlist :\n",
    "        if not (gross_token.startswith(\"@\") or\n",
    "                gross_token.startswith(\"#\") or\n",
    "                gross_token.startswith(\"http\")) :\n",
    "            text += gross_token + \" \"\n",
    "    return text[:-1]\n",
    "def remove_stopwords(tokenlist:list[str]) -> list[str] :\n",
    "    stoplist = stopwords.words('english')\n",
    "    newtokenlist = []\n",
    "    for token in tokenlist :\n",
    "        if not token in stoplist :\n",
    "            newtokenlist.append(token)\n",
    "    return newtokenlist\n",
    "def remove_nonalpha(tokenlist:list[str]) -> list[str] :\n",
    "    newtokenlist = []\n",
    "    for tkn in tokenlist :\n",
    "        newtkn = \"\"\n",
    "        for char in tkn :\n",
    "            if char.isalpha() :\n",
    "                newtkn += char\n",
    "        if newtkn != \"\" : newtokenlist.append(newtkn)\n",
    "    return newtokenlist\n",
    "def preprocess(text:str) -> str :\n",
    "    text = remove_ats_hashtags_and_links(text)\n",
    "    text = text.lower()\n",
    "    tokenlist = nltk.word_tokenize(text)\n",
    "    tokenlist = remove_stopwords(tokenlist)\n",
    "    lemmatizer = nltk.WordNetLemmatizer()\n",
    "    lemmalist = [lemmatizer.lemmatize(token) for token in tokenlist]\n",
    "    lemmalist = remove_nonalpha(lemmalist)\n",
    "    text = \"\"\n",
    "    for tkn in lemmalist :\n",
    "        text += tkn + \" \"\n",
    "    text = text[ : -1]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_clean = dataset_clean.copy() # Defrag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "12900\n",
      "13000\n",
      "13100\n",
      "13200\n",
      "13300\n",
      "13400\n",
      "13500\n",
      "13600\n",
      "13700\n",
      "13800\n",
      "13900\n",
      "14000\n",
      "14100\n",
      "14200\n",
      "14300\n",
      "14400\n",
      "14500\n",
      "14600\n"
     ]
    }
   ],
   "source": [
    "processed_text = []\n",
    "classes = []\n",
    "index = []\n",
    "for i, (_, row) in enumerate(dataset_clean.iterrows()) :\n",
    "    if i % 100 == 0 : \n",
    "        print(i)\n",
    "    processed = preprocess(row[\"text\"])\n",
    "    if processed == \"\" : processed = \" \"\n",
    "    processed_text.append(processed)\n",
    "    classes.append([\"negative\", \"neutral\", \"positive\"].index(row[\"airline_sentiment\"]))\n",
    "    index.append(row.name)\n",
    "processed_text_column = pd.Series(processed_text, index, name=\"text\")\n",
    "classes_column = pd.Series(classes, index, name=\"class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_processed = pd.concat([processed_text_column, classes_column], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>570306133677760513</th>\n",
       "      <td>said</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570301130888122368</th>\n",
       "      <td>plus ve added commercial experience tacky</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570301083672813571</th>\n",
       "      <td>nt today must mean need take another trip</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570301031407624196</th>\n",
       "      <td>s really aggressive blast obnoxious entertainm...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570300817074462722</th>\n",
       "      <td>s really big bad thing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569587686496825344</th>\n",
       "      <td>thank got different flight chicago</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569587371693355008</th>\n",
       "      <td>leaving minute late flight warning communicati...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569587242672398336</th>\n",
       "      <td>please bring american airline</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569587188687634433</th>\n",
       "      <td>money change flight nt answer phone suggestion...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569587140490866689</th>\n",
       "      <td>ppl need know many seat next flight plz put u ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14640 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 text  class\n",
       "570306133677760513                                               said      1\n",
       "570301130888122368          plus ve added commercial experience tacky      2\n",
       "570301083672813571          nt today must mean need take another trip      1\n",
       "570301031407624196  s really aggressive blast obnoxious entertainm...      0\n",
       "570300817074462722                             s really big bad thing      0\n",
       "...                                                               ...    ...\n",
       "569587686496825344                 thank got different flight chicago      2\n",
       "569587371693355008  leaving minute late flight warning communicati...      0\n",
       "569587242672398336                      please bring american airline      1\n",
       "569587188687634433  money change flight nt answer phone suggestion...      0\n",
       "569587140490866689  ppl need know many seat next flight plz put u ...      1\n",
       "\n",
       "[14640 rows x 2 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_processed = dataset_processed.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_processed.to_csv(f\"{dataset_folder}/TweetsProcessed.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb071969cc081d156db4658a52cc12ff3302089485c0c8cb524fcf02c6362775"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
