{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attention(inputs, mask, n_heads, causal) :\n",
    "    if n_heads == 1 :\n",
    "        attention = keras.layers.Attention(causal=causal)(\n",
    "            [\n",
    "            inputs, \n",
    "            inputs\n",
    "            ],\n",
    "            mask=[ \n",
    "            mask, \n",
    "            mask\n",
    "            ]\n",
    "        )\n",
    "    elif n_heads > 1 :\n",
    "        attentions = []\n",
    "        for _ in range(n_heads) :\n",
    "            attentions.append(\n",
    "                keras.layers.Attention(causal=causal)(\n",
    "                    [\n",
    "                        inputs, \n",
    "                        inputs\n",
    "                    ],\n",
    "                    mask=[ \n",
    "                        mask, \n",
    "                        mask\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "        attention = keras.layers.Add()(attentions)\n",
    "        attention = keras.layers.BatchNormalization()(attention)\n",
    "    else :\n",
    "        return inputs\n",
    "    return attention\n",
    "\n",
    "def pooling_on_mask(inputs_mask:tf.Tensor) :\n",
    "    inputs_mask = tf.cast(inputs_mask, tf.int8)\n",
    "    shape = inputs_mask.get_shape().as_list()\n",
    "    inputs_mask = keras.layers.Reshape((shape[1], 1))(inputs_mask)\n",
    "    inputs_mask = keras.layers.MaxPooling1D(pool_size=2, padding='same')(inputs_mask)\n",
    "    shape = inputs_mask.get_shape().as_list()\n",
    "    inputs_mask = keras.layers.Reshape((shape[1],))(inputs_mask)\n",
    "    inputs_mask = tf.cast(inputs_mask, tf.bool)\n",
    "    return inputs_mask\n",
    "\n",
    "def get_model(vocab_size, \n",
    "                embed_dim,\n",
    "                max_len=256,\n",
    "                n_classes=1,\n",
    "                with_attention=True,\n",
    "                return_sequences_on_end=False,\n",
    "                emb_trainable=True) :\n",
    "    inputs      = tf.keras.Input(shape=(max_len,), dtype='int32')\n",
    "    inputs_mask = tf.keras.Input(shape=(max_len,), dtype='bool')\n",
    "    \n",
    "    embedding_layer = keras.layers.Embedding(vocab_size, embed_dim, input_length=max_len, mask_zero=True, trainable=emb_trainable)\n",
    "    embedding = embedding_layer(inputs)\n",
    "    \n",
    "    enc_conv1 = keras.layers.Conv1D(filters=128, kernel_size=3, activation='relu', padding='same')(embedding)\n",
    "    \n",
    "    lstm2 = keras.layers.LSTM(units=64, return_sequences=True)([enc_conv1], mask=inputs_mask)\n",
    "    last  = lstm2\n",
    "    \n",
    "    if with_attention :\n",
    "        attention = keras.layers.Attention(causal=False)(\n",
    "            [\n",
    "            last, \n",
    "            last\n",
    "            ],\n",
    "            mask=[ \n",
    "            inputs_mask, \n",
    "            inputs_mask\n",
    "            ]\n",
    "        )\n",
    "        last  = attention\n",
    "    \n",
    "    lstm3 = keras.layers.LSTM(units=64, return_sequences=return_sequences_on_end)([last], mask=inputs_mask)\n",
    "    last  = lstm3\n",
    "\n",
    "    if return_sequences_on_end :\n",
    "        pool = keras.layers.GlobalAveragePooling1D()(last)\n",
    "        last = pool\n",
    "    \n",
    "    drop1 = keras.layers.Dropout(0.05)(last)\n",
    "    last  = drop1\n",
    "    \n",
    "    outputs = keras.layers.Dense(n_classes, activation='sigmoid' if n_classes==1 else 'softmax')(last)\n",
    "\n",
    "    model = keras.models.Model(inputs=[inputs, inputs_mask], outputs=outputs)\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model, embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def get_word_index(sentences) :\n",
    "    all_tokens = []\n",
    "    for txt in sentences :\n",
    "        all_tokens += txt.split()\n",
    "\n",
    "    tokens = pd.Series(all_tokens, range(len(all_tokens)), name=\"tokens\")\n",
    "    types = tokens.unique()\n",
    "    word_index = {word : i for i, word in enumerate([\"<pad>\", \"<unk>\"] + list(types))}\n",
    "    \n",
    "    def decode_review(text):\n",
    "        reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "        return ' '.join([reverse_word_index.get(i, '?') for i in text])\n",
    "    \n",
    "    return word_index, decode_review\n",
    "\n",
    "def get_dataset(dataframe, word_index, n_classes, max_len=256) :\n",
    "    index_series, x_series, y_series = dataframe.index, dataframe[\"text\"], dataframe[\"class\"]\n",
    "\n",
    "    index = list(index_series)\n",
    "\n",
    "    x_list = [txt.split() for txt in list(x_series)]\n",
    "    \n",
    "    x_seq = []\n",
    "    for tknlst in x_list :\n",
    "        seq = []\n",
    "        for tkn in tknlst :\n",
    "            try :\n",
    "                seq.append(word_index[tkn])\n",
    "            except KeyError :\n",
    "                seq.append(word_index[\"<unk>\"])\n",
    "        seq = (seq + [0] * (max_len - len(seq))) if (len(seq) < max_len) else (seq[ : max_len])\n",
    "        x_seq.append(seq)\n",
    "\n",
    "    x = np.array(x_seq, dtype=int) \n",
    "    mask = x != 0\n",
    "    \n",
    "    if n_classes == 1 :\n",
    "        y_int = [1 if lb >= .5 else 0 for lb in list(y_series)]\n",
    "\n",
    "        y = np.array(y_int, dtype=int) \n",
    "    elif n_classes > 1 :\n",
    "        y = np.zeros((y_series.shape[0], n_classes), dtype=int)\n",
    "        for i, label in enumerate(list(y_series)) :\n",
    "            y[i][label] = 1\n",
    "    else :\n",
    "        raise Exception()\n",
    "\n",
    "    return index, x, mask, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [\n",
    "    {\n",
    "        \"experiment_name\" : f\"lstm_WITH_ATTENTION_embed768\",\n",
    "        \"load_weights_from\" : None,\n",
    "        \"args\" : {\n",
    "            \"vocab_size\" : None,\n",
    "            \"embed_dim\" : 768,\n",
    "            \"n_classes\" : 3,\n",
    "            \"with_attention\" : True,\n",
    "            \"emb_trainable\" : True,\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"experiment_name\" : f\"lstm_NO_ATTENTION_embed768\",\n",
    "        \"load_weights_from\" : None,\n",
    "        \"args\" : {\n",
    "            \"vocab_size\" : None,\n",
    "            \"embed_dim\" : 768,\n",
    "            \"n_classes\" : 3,\n",
    "            \"with_attention\" : False,\n",
    "            \"emb_trainable\" : True,\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"experiment_name\" : f\"lstm_WITH_ATTENTION_RETSEQ_embed768\",\n",
    "        \"load_weights_from\" : None,\n",
    "        \"args\" : {\n",
    "            \"vocab_size\" : None,\n",
    "            \"embed_dim\" : 768,\n",
    "            \"n_classes\" : 3,\n",
    "            \"with_attention\" : True,\n",
    "            \"return_sequences_on_end\" : True,\n",
    "            \"emb_trainable\" : True,\n",
    "        }\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "../resources/output/TweetsProcessed2/lstm/checkpoint_lstm_WITH_ATTENTION_embed768/fold1.hdf5\n",
      "==================================================\n",
      "../resources/output/TweetsProcessed2/lstm/checkpoint_lstm_WITH_ATTENTION_embed768/fold2.hdf5\n",
      "==================================================\n",
      "../resources/output/TweetsProcessed2/lstm/checkpoint_lstm_WITH_ATTENTION_embed768/fold3.hdf5\n",
      "==================================================\n",
      "../resources/output/TweetsProcessed2/lstm/checkpoint_lstm_WITH_ATTENTION_embed768/fold4.hdf5\n",
      "==================================================\n",
      "../resources/output/TweetsProcessed2/lstm/checkpoint_lstm_WITH_ATTENTION_embed768/fold5.hdf5\n",
      "==================================================\n",
      "../resources/output/TweetsProcessed2/lstm/checkpoint_lstm_WITH_ATTENTION_embed768/fold6.hdf5\n",
      "==================================================\n",
      "../resources/output/TweetsProcessed2/lstm/checkpoint_lstm_WITH_ATTENTION_embed768/fold7.hdf5\n",
      "==================================================\n",
      "../resources/output/TweetsProcessed2/lstm/checkpoint_lstm_WITH_ATTENTION_embed768/fold8.hdf5\n",
      "==================================================\n",
      "../resources/output/TweetsProcessed2/lstm/checkpoint_lstm_WITH_ATTENTION_embed768/fold9.hdf5\n",
      "==================================================\n",
      "../resources/output/TweetsProcessed2/lstm/checkpoint_lstm_WITH_ATTENTION_embed768/fold10.hdf5\n",
      "==================================================\n",
      "../resources/output/TweetsProcessed2/lstm/checkpoint_lstm_NO_ATTENTION_embed768/fold1.hdf5\n",
      "==================================================\n",
      "../resources/output/TweetsProcessed2/lstm/checkpoint_lstm_NO_ATTENTION_embed768/fold2.hdf5\n",
      "==================================================\n",
      "../resources/output/TweetsProcessed2/lstm/checkpoint_lstm_NO_ATTENTION_embed768/fold3.hdf5\n",
      "13176 (13176, 256) (13176, 256) (13176, 3)\n",
      "<start> iad to jfk still has n't boarded what's today's excuse and how am i gon na get to work <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> [1 0 0]\n",
      "1464 (1464, 256) (1464, 256) (1464, 3)\n",
      "<start> tks for reply psp employees blamed late flight departure on <unk> when main reasons were <unk> flt late flight amp insufficient ground crew to handle <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> [1 0 0]\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_11 (InputLayer)          [(None, 256)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_5 (Embedding)        (None, 256, 768)     9319680     ['input_11[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 256, 128)     295040      ['embedding_5[0][0]']            \n",
      "                                                                                                  \n",
      " input_12 (InputLayer)          [(None, 256)]        0           []                               \n",
      "                                                                                                  \n",
      " lstm_10 (LSTM)                 (None, 256, 64)      49408       ['conv1d_5[0][0]',               \n",
      "                                                                  'input_12[0][0]']               \n",
      "                                                                                                  \n",
      " lstm_11 (LSTM)                 (None, 64)           33024       ['lstm_10[0][0]',                \n",
      "                                                                  'input_12[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 64)           0           ['lstm_11[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 3)            195         ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 9,697,347\n",
      "Trainable params: 9,697,347\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "12101 (12135, 768) 12103\n",
      "Epoch 1/6\n",
      "206/206 [==============================] - ETA: 0s - loss: 0.6725 - accuracy: 0.7270\n",
      "Epoch 1: val_loss improved from inf to 0.61737, saving model to ../resources/output/TweetsProcessed2/lstm/checkpoint_lstm_NO_ATTENTION_embed768\\fold3.hdf5\n",
      "206/206 [==============================] - 166s 777ms/step - loss: 0.6725 - accuracy: 0.7270 - val_loss: 0.6174 - val_accuracy: 0.7404\n",
      "Epoch 2/6\n",
      "206/206 [==============================] - ETA: 0s - loss: 0.4576 - accuracy: 0.8232\n",
      "Epoch 2: val_loss improved from 0.61737 to 0.61511, saving model to ../resources/output/TweetsProcessed2/lstm/checkpoint_lstm_NO_ATTENTION_embed768\\fold3.hdf5\n",
      "206/206 [==============================] - 200s 972ms/step - loss: 0.4576 - accuracy: 0.8232 - val_loss: 0.6151 - val_accuracy: 0.7630\n",
      "Epoch 3/6\n",
      "206/206 [==============================] - ETA: 0s - loss: 0.3108 - accuracy: 0.8859\n",
      "Epoch 3: val_loss improved from 0.61511 to 0.59271, saving model to ../resources/output/TweetsProcessed2/lstm/checkpoint_lstm_NO_ATTENTION_embed768\\fold3.hdf5\n",
      "206/206 [==============================] - 203s 985ms/step - loss: 0.3108 - accuracy: 0.8859 - val_loss: 0.5927 - val_accuracy: 0.7807\n",
      "Epoch 4/6\n",
      "206/206 [==============================] - ETA: 0s - loss: 0.1990 - accuracy: 0.9304\n",
      "Epoch 4: val_loss did not improve from 0.59271\n",
      "206/206 [==============================] - 201s 974ms/step - loss: 0.1990 - accuracy: 0.9304 - val_loss: 0.7033 - val_accuracy: 0.7773\n",
      "Epoch 5/6\n",
      "206/206 [==============================] - ETA: 0s - loss: 0.1289 - accuracy: 0.9567\n",
      "Epoch 5: val_loss did not improve from 0.59271\n",
      "206/206 [==============================] - 203s 986ms/step - loss: 0.1289 - accuracy: 0.9567 - val_loss: 0.8255 - val_accuracy: 0.7732\n",
      "Epoch 6/6\n",
      "206/206 [==============================] - ETA: 0s - loss: 0.0944 - accuracy: 0.9684\n",
      "Epoch 6: val_loss did not improve from 0.59271\n",
      "206/206 [==============================] - 184s 895ms/step - loss: 0.0944 - accuracy: 0.9684 - val_loss: 0.9325 - val_accuracy: 0.7678\n",
      "46/46 [==============================] - 11s 205ms/step\n",
      "{'model': '../resources/output/TweetsProcessed2/lstm/checkpoint_lstm_NO_ATTENTION_embed768/fold3.hdf5', 'accuracy': 0.7807377049180327}\n",
      "==================================================\n",
      "../resources/output/TweetsProcessed2/lstm/checkpoint_lstm_NO_ATTENTION_embed768/fold4.hdf5\n",
      "13176 (13176, 256) (13176, 256) (13176, 3)\n",
      "<start> iad to jfk still has n't boarded what's today's excuse and how am i gon na get to work <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> [1 0 0]\n",
      "1464 (1464, 256) (1464, 256) (1464, 3)\n",
      "<start> was in a line a mile long at sky harbor this morning your staff was courteous and <unk> thank you <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> [0 0 1]\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_13 (InputLayer)          [(None, 256)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_6 (Embedding)        (None, 256, 768)     9319680     ['input_13[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 256, 128)     295040      ['embedding_6[0][0]']            \n",
      "                                                                                                  \n",
      " input_14 (InputLayer)          [(None, 256)]        0           []                               \n",
      "                                                                                                  \n",
      " lstm_12 (LSTM)                 (None, 256, 64)      49408       ['conv1d_6[0][0]',               \n",
      "                                                                  'input_14[0][0]']               \n",
      "                                                                                                  \n",
      " lstm_13 (LSTM)                 (None, 64)           33024       ['lstm_12[0][0]',                \n",
      "                                                                  'input_14[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 64)           0           ['lstm_13[0][0]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 3)            195         ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 9,697,347\n",
      "Trainable params: 9,697,347\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "12127 (12135, 768) 12129\n",
      "Epoch 1/6\n",
      "206/206 [==============================] - ETA: 0s - loss: 0.6727 - accuracy: 0.7237\n",
      "Epoch 1: val_loss improved from inf to 0.56589, saving model to ../resources/output/TweetsProcessed2/lstm/checkpoint_lstm_NO_ATTENTION_embed768\\fold4.hdf5\n",
      "206/206 [==============================] - 181s 847ms/step - loss: 0.6727 - accuracy: 0.7237 - val_loss: 0.5659 - val_accuracy: 0.7678\n",
      "Epoch 2/6\n",
      "206/206 [==============================] - ETA: 0s - loss: 0.4729 - accuracy: 0.8168\n",
      "Epoch 2: val_loss improved from 0.56589 to 0.54232, saving model to ../resources/output/TweetsProcessed2/lstm/checkpoint_lstm_NO_ATTENTION_embed768\\fold4.hdf5\n",
      "206/206 [==============================] - 157s 762ms/step - loss: 0.4729 - accuracy: 0.8168 - val_loss: 0.5423 - val_accuracy: 0.7821\n",
      "Epoch 3/6\n",
      " 24/206 [==>...........................] - ETA: 2:33 - loss: 0.3222 - accuracy: 0.8750"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\T-Gamer\\Documents\\SideDrive\\UFMA\\2022.1\\Topicos Especiais (NLP)\\Exercicios\\Trabalho Final\\Implementação\\source\\exp1_lstm_folds.ipynb Célula: 5\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/T-Gamer/Documents/SideDrive/UFMA/2022.1/Topicos%20Especiais%20%28NLP%29/Exercicios/Trabalho%20Final/Implementa%C3%A7%C3%A3o/source/exp1_lstm_folds.ipynb#W4sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m emb_layer\u001b[39m.\u001b[39mtrainable \u001b[39m=\u001b[39m experiment[\u001b[39m'\u001b[39m\u001b[39margs\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39memb_trainable\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/T-Gamer/Documents/SideDrive/UFMA/2022.1/Topicos%20Especiais%20%28NLP%29/Exercicios/Trabalho%20Final/Implementa%C3%A7%C3%A3o/source/exp1_lstm_folds.ipynb#W4sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/T-Gamer/Documents/SideDrive/UFMA/2022.1/Topicos%20Especiais%20%28NLP%29/Exercicios/Trabalho%20Final/Implementa%C3%A7%C3%A3o/source/exp1_lstm_folds.ipynb#W4sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m             loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m experiment[\u001b[39m\"\u001b[39m\u001b[39margs\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mn_classes\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/T-Gamer/Documents/SideDrive/UFMA/2022.1/Topicos%20Especiais%20%28NLP%29/Exercicios/Trabalho%20Final/Implementa%C3%A7%C3%A3o/source/exp1_lstm_folds.ipynb#W4sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m             metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/T-Gamer/Documents/SideDrive/UFMA/2022.1/Topicos%20Especiais%20%28NLP%29/Exercicios/Trabalho%20Final/Implementa%C3%A7%C3%A3o/source/exp1_lstm_folds.ipynb#W4sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit([x_train, mask_train],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/T-Gamer/Documents/SideDrive/UFMA/2022.1/Topicos%20Especiais%20%28NLP%29/Exercicios/Trabalho%20Final/Implementa%C3%A7%C3%A3o/source/exp1_lstm_folds.ipynb#W4sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m                     y_train,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/T-Gamer/Documents/SideDrive/UFMA/2022.1/Topicos%20Especiais%20%28NLP%29/Exercicios/Trabalho%20Final/Implementa%C3%A7%C3%A3o/source/exp1_lstm_folds.ipynb#W4sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m                     epochs\u001b[39m=\u001b[39;49m\u001b[39m6\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/T-Gamer/Documents/SideDrive/UFMA/2022.1/Topicos%20Especiais%20%28NLP%29/Exercicios/Trabalho%20Final/Implementa%C3%A7%C3%A3o/source/exp1_lstm_folds.ipynb#W4sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m                     batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/T-Gamer/Documents/SideDrive/UFMA/2022.1/Topicos%20Especiais%20%28NLP%29/Exercicios/Trabalho%20Final/Implementa%C3%A7%C3%A3o/source/exp1_lstm_folds.ipynb#W4sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m                     validation_data\u001b[39m=\u001b[39;49m([x_valid, mask_valid], y_valid),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/T-Gamer/Documents/SideDrive/UFMA/2022.1/Topicos%20Especiais%20%28NLP%29/Exercicios/Trabalho%20Final/Implementa%C3%A7%C3%A3o/source/exp1_lstm_folds.ipynb#W4sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m                     callbacks\u001b[39m=\u001b[39;49m[\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/T-Gamer/Documents/SideDrive/UFMA/2022.1/Topicos%20Especiais%20%28NLP%29/Exercicios/Trabalho%20Final/Implementa%C3%A7%C3%A3o/source/exp1_lstm_folds.ipynb#W4sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m                         keras\u001b[39m.\u001b[39;49mcallbacks\u001b[39m.\u001b[39;49mModelCheckpoint(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/T-Gamer/Documents/SideDrive/UFMA/2022.1/Topicos%20Especiais%20%28NLP%29/Exercicios/Trabalho%20Final/Implementa%C3%A7%C3%A3o/source/exp1_lstm_folds.ipynb#W4sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m                             checkpoint_path,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/T-Gamer/Documents/SideDrive/UFMA/2022.1/Topicos%20Especiais%20%28NLP%29/Exercicios/Trabalho%20Final/Implementa%C3%A7%C3%A3o/source/exp1_lstm_folds.ipynb#W4sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m                             save_best_only\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/T-Gamer/Documents/SideDrive/UFMA/2022.1/Topicos%20Especiais%20%28NLP%29/Exercicios/Trabalho%20Final/Implementa%C3%A7%C3%A3o/source/exp1_lstm_folds.ipynb#W4sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m                             save_weights_only\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/T-Gamer/Documents/SideDrive/UFMA/2022.1/Topicos%20Especiais%20%28NLP%29/Exercicios/Trabalho%20Final/Implementa%C3%A7%C3%A3o/source/exp1_lstm_folds.ipynb#W4sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m                             verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/T-Gamer/Documents/SideDrive/UFMA/2022.1/Topicos%20Especiais%20%28NLP%29/Exercicios/Trabalho%20Final/Implementa%C3%A7%C3%A3o/source/exp1_lstm_folds.ipynb#W4sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m                         )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/T-Gamer/Documents/SideDrive/UFMA/2022.1/Topicos%20Especiais%20%28NLP%29/Exercicios/Trabalho%20Final/Implementa%C3%A7%C3%A3o/source/exp1_lstm_folds.ipynb#W4sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m                     ],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/T-Gamer/Documents/SideDrive/UFMA/2022.1/Topicos%20Especiais%20%28NLP%29/Exercicios/Trabalho%20Final/Implementa%C3%A7%C3%A3o/source/exp1_lstm_folds.ipynb#W4sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m                     verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/T-Gamer/Documents/SideDrive/UFMA/2022.1/Topicos%20Especiais%20%28NLP%29/Exercicios/Trabalho%20Final/Implementa%C3%A7%C3%A3o/source/exp1_lstm_folds.ipynb#W4sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m model\u001b[39m.\u001b[39mload_weights(checkpoint_path)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/T-Gamer/Documents/SideDrive/UFMA/2022.1/Topicos%20Especiais%20%28NLP%29/Exercicios/Trabalho%20Final/Implementa%C3%A7%C3%A3o/source/exp1_lstm_folds.ipynb#W4sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m preds \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict([x_valid, mask_valid])\n",
      "File \u001b[1;32mc:\\Users\\T-Gamer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\T-Gamer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\T-Gamer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\T-Gamer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\T-Gamer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\T-Gamer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\T-Gamer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\T-Gamer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\T-Gamer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from statistics import mean\n",
    "\n",
    "n_folds = 10\n",
    "dataset_folder = \"TwitterAirlines\"\n",
    "dataset_name   = \"TweetsProcessed2\"\n",
    "for experiment in experiments :\n",
    "    checkpoint_dir  = f\"../resources/output/{dataset_name}/lstm/checkpoint_{experiment['experiment_name']}\"\n",
    "    \n",
    "    folds_dfs, embeddings_dfs = [], []\n",
    "    for i_fold in range(n_folds) :\n",
    "        fold_df       = pd.read_csv(f\"../resources/datasets/{dataset_folder}/folds/{dataset_name}_Fold{i_fold + 1}.csv\", index_col=0)\n",
    "        embedding_df = pd.read_csv(f\"../resources/embeddings/{dataset_folder}/{dataset_name}_Fold{i_fold + 1}_dim{experiment['args']['embed_dim']}.csv\", index_col=0)\n",
    "        \n",
    "        folds_dfs.append(fold_df)\n",
    "        embeddings_dfs.append(embedding_df)\n",
    "    \n",
    "    evals = []\n",
    "    for i_fold in range(n_folds) :\n",
    "        print(\"=\" * 50)\n",
    "        checkpoint_path = f\"{checkpoint_dir}/fold{i_fold + 1}.hdf5\"\n",
    "        print(checkpoint_path)\n",
    "        if os.path.exists(checkpoint_path) : continue\n",
    "\n",
    "        embeddings_df = embeddings_dfs[i_fold]\n",
    "\n",
    "        train_dataframe = pd.concat(folds_dfs[ : i_fold] + folds_dfs[i_fold + 1 : ])\n",
    "        valid_dataframe = folds_dfs[i_fold]\n",
    "        \n",
    "        word_index, decode_review = get_word_index(train_dataframe[\"text\"])\n",
    "        if experiment[\"args\"][\"vocab_size\"] is None :\n",
    "            experiment[\"args\"][\"vocab_size\"] = len(word_index)\n",
    "\n",
    "        ids_train, x_train, mask_train, y_train = get_dataset(train_dataframe, word_index, n_classes=experiment[\"args\"][\"n_classes\"])\n",
    "        print(len(ids_train), x_train.shape, mask_train.shape, y_train.shape)\n",
    "        print(decode_review(x_train[1]), y_train[1])\n",
    "        \n",
    "        ids_valid, x_valid, mask_valid, y_valid = get_dataset(valid_dataframe, word_index, n_classes=experiment[\"args\"][\"n_classes\"])\n",
    "        print(len(ids_valid), x_valid.shape, mask_valid.shape, y_valid.shape)\n",
    "        print(decode_review(x_valid[1]), y_valid[1])\n",
    "\n",
    "        model, emb_layer = get_model(**experiment['args'])\n",
    "\n",
    "        emb_wgts = emb_layer.get_weights()\n",
    "        print(embeddings_df.shape[0], emb_wgts[0].shape, len(word_index))\n",
    "        emb_wgts[0][0] = embeddings_df.iloc[0].values\n",
    "        emb_wgts[0][1 - embeddings_df.shape[0] : ] = embeddings_df.values[1:]\n",
    "        emb_layer.set_weights(emb_wgts)\n",
    "\n",
    "        if not experiment['load_weights_from'] is None :\n",
    "            model.load_weights(experiment['load_weights_from'])\n",
    "        emb_layer.trainable = experiment['args']['emb_trainable']\n",
    "\n",
    "        model.compile(optimizer='adam',\n",
    "                    loss='binary_crossentropy' if experiment[\"args\"][\"n_classes\"] == 1 else 'categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "        history = model.fit([x_train, mask_train],\n",
    "                            y_train,\n",
    "                            epochs=6,\n",
    "                            batch_size=64,\n",
    "                            validation_data=([x_valid, mask_valid], y_valid),\n",
    "                            callbacks=[\n",
    "                                keras.callbacks.ModelCheckpoint(\n",
    "                                    checkpoint_path,\n",
    "                                    save_best_only=True,\n",
    "                                    save_weights_only=False,\n",
    "                                    verbose=1\n",
    "                                )\n",
    "                            ],\n",
    "                            verbose=1)\n",
    "\n",
    "        model.load_weights(checkpoint_path)\n",
    "\n",
    "        preds = model.predict([x_valid, mask_valid])\n",
    "\n",
    "        if experiment[\"args\"][\"n_classes\"] == 1 :\n",
    "            preds_df = pd.DataFrame(preds, index=ids_valid, columns=[\"predictions\"])\n",
    "            dataset_with_preds_df = pd.concat([valid_dataframe, preds_df], axis=1)\n",
    "            \n",
    "            hits, total = 0, 0\n",
    "            for _, row in dataset_with_preds_df.iterrows() :\n",
    "                total += 1\n",
    "                pred  = row[\"predictions\"] >= .5\n",
    "                label = row[\"class\"]       >= .5\n",
    "                if pred == label : \n",
    "                    hits += 1\n",
    "            accuracy = hits / total\n",
    "\n",
    "            hits, total = 0, 0\n",
    "            for _, row in dataset_with_preds_df.iterrows() :\n",
    "                total += 1\n",
    "                pred  = row[\"predictions\"]\n",
    "                label = row[\"class\"]\n",
    "                diff = label - pred\n",
    "                hits += abs(diff)\n",
    "            avg_dev = hits / total\n",
    "\n",
    "            true_positives, true_negatives, false_positives, false_negatives = 0, 0, 0, 0\n",
    "            for _, row in dataset_with_preds_df.iterrows() :\n",
    "                pred  = row[\"predictions\"] >= .5\n",
    "                label = row[\"class\"]       >= .5\n",
    "                if pred == label :\n",
    "                    if pred :\n",
    "                        true_positives  += 1\n",
    "                    else :\n",
    "                        true_negatives  += 1\n",
    "                else :\n",
    "                    if pred :\n",
    "                        false_positives += 1\n",
    "                    else :\n",
    "                        false_negatives += 1\n",
    "            print(true_positives, true_negatives, false_positives, false_negatives)\n",
    "\n",
    "            precision = true_positives / (true_positives + false_positives)\n",
    "            recall = true_positives / (true_positives + false_negatives)\n",
    "            f1 = (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "            eval_dict = {\n",
    "                'model'     : checkpoint_path,\n",
    "                'accuracy'  : accuracy,\n",
    "                'precision' : precision,\n",
    "                'recall'    : recall,\n",
    "                'f1-score'  : f1,\n",
    "                'detail'    : {\n",
    "                    \"true_positives\"  : true_positives,\n",
    "                    \"true_negatives\"  : true_negatives,\n",
    "                    \"false_positives\" : false_positives,\n",
    "                    \"false_negatives\" : false_negatives\n",
    "                }\n",
    "            }\n",
    "        else :\n",
    "            preds_df = pd.DataFrame(preds, index=ids_valid, columns=[\"preds_0\", \"preds_1\", \"preds_2\"])\n",
    "            dataset_with_preds_df = pd.concat([valid_dataframe, preds_df], axis=1)\n",
    "            dataset_with_preds_df.to_csv(f\"{checkpoint_dir}/fold{i_fold}-predictions.csv\")\n",
    "            \n",
    "            hits, total = 0, 0\n",
    "            for _, row in dataset_with_preds_df.iterrows() :\n",
    "                total += 1\n",
    "                pred  = np.argmax([row[col] for col in [\"preds_0\", \"preds_1\", \"preds_2\"]])\n",
    "                label = row[\"class\"]\n",
    "                if pred == label : \n",
    "                    hits += 1\n",
    "            accuracy = hits / total\n",
    "            eval_dict = {\n",
    "                'model'     : checkpoint_path,\n",
    "                'accuracy'  : accuracy\n",
    "            }\n",
    "\n",
    "        print(eval_dict)\n",
    "\n",
    "        with open(f\"{eval_dict['model']}-eval-dict.json\", \"w\") as f :\n",
    "            f.write(json.dumps(eval_dict, indent=4))\n",
    "\n",
    "        evals.append(eval_dict)\n",
    "\n",
    "        del model \n",
    "    if len(evals) == 0 : continue\n",
    "    final_metrics = {\n",
    "        \"experiment\" : experiment[\"experiment_name\"],\n",
    "        'accuracy'  : mean([fold_metrics[\"accuracy\"] for fold_metrics in evals])\n",
    "    }\n",
    "    if 'precision' in evals[0].keys() :\n",
    "        final_metrics['precision'] = mean([fold_metrics[\"precision\"] for fold_metrics in evals]),\n",
    "    if 'recall' in evals[0].keys() :\n",
    "        final_metrics['recall']    = mean([fold_metrics[\"recall\"] for fold_metrics in evals]),\n",
    "    if 'f1-score' in evals[0].keys() :\n",
    "        final_metrics['f1-score']  = mean([fold_metrics[\"f1\"] for fold_metrics in evals]),\n",
    "    if 'detail' in evals[0].keys() :\n",
    "        final_metrics['detail'] = {\n",
    "            \"true_positives\"  : sum([fold_metrics[\"detail\"][\"true_positives\"]  for fold_metrics in evals]),\n",
    "            \"true_negatives\"  : sum([fold_metrics[\"detail\"][\"true_negatives\"]  for fold_metrics in evals]),\n",
    "            \"false_positives\" : sum([fold_metrics[\"detail\"][\"false_positives\"] for fold_metrics in evals]),\n",
    "            \"false_negatives\" : sum([fold_metrics[\"detail\"][\"false_negatives\"] for fold_metrics in evals])\n",
    "        }\n",
    "    with open(f\"{checkpoint_dir}/final-eval-dict.json\", \"w\") as f :\n",
    "        f.write(json.dumps(eval_dict, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "      <th>768</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;start&gt;</th>\n",
       "      <td>-0.251972</td>\n",
       "      <td>-0.335857</td>\n",
       "      <td>0.743956</td>\n",
       "      <td>0.287609</td>\n",
       "      <td>-0.320067</td>\n",
       "      <td>-0.336197</td>\n",
       "      <td>0.651577</td>\n",
       "      <td>-0.417630</td>\n",
       "      <td>0.072657</td>\n",
       "      <td>0.669512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118542</td>\n",
       "      <td>0.013129</td>\n",
       "      <td>-0.103702</td>\n",
       "      <td>0.214072</td>\n",
       "      <td>0.223253</td>\n",
       "      <td>0.165746</td>\n",
       "      <td>-0.625366</td>\n",
       "      <td>-0.433057</td>\n",
       "      <td>-0.647071</td>\n",
       "      <td>-0.493110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>-0.095761</td>\n",
       "      <td>-0.244435</td>\n",
       "      <td>0.169767</td>\n",
       "      <td>-0.254720</td>\n",
       "      <td>0.520574</td>\n",
       "      <td>0.380848</td>\n",
       "      <td>-0.152164</td>\n",
       "      <td>0.410601</td>\n",
       "      <td>0.975136</td>\n",
       "      <td>0.334161</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.455171</td>\n",
       "      <td>-0.563830</td>\n",
       "      <td>0.425149</td>\n",
       "      <td>-0.744738</td>\n",
       "      <td>0.315320</td>\n",
       "      <td>-1.070223</td>\n",
       "      <td>-0.815350</td>\n",
       "      <td>0.106142</td>\n",
       "      <td>0.148487</td>\n",
       "      <td>-0.391389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>-0.040541</td>\n",
       "      <td>-1.178647</td>\n",
       "      <td>0.772364</td>\n",
       "      <td>0.711954</td>\n",
       "      <td>0.177214</td>\n",
       "      <td>-0.639962</td>\n",
       "      <td>-0.159563</td>\n",
       "      <td>0.261875</td>\n",
       "      <td>0.473067</td>\n",
       "      <td>-0.223687</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.444203</td>\n",
       "      <td>-0.343703</td>\n",
       "      <td>-0.317150</td>\n",
       "      <td>-0.642309</td>\n",
       "      <td>1.033737</td>\n",
       "      <td>0.581608</td>\n",
       "      <td>0.067017</td>\n",
       "      <td>-0.575224</td>\n",
       "      <td>0.700265</td>\n",
       "      <td>-0.863741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>-0.406263</td>\n",
       "      <td>0.581536</td>\n",
       "      <td>0.150963</td>\n",
       "      <td>0.089914</td>\n",
       "      <td>-0.085831</td>\n",
       "      <td>-0.187691</td>\n",
       "      <td>-0.108174</td>\n",
       "      <td>0.237551</td>\n",
       "      <td>0.576532</td>\n",
       "      <td>0.273172</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.107218</td>\n",
       "      <td>-0.156319</td>\n",
       "      <td>-0.019238</td>\n",
       "      <td>-0.439631</td>\n",
       "      <td>-0.072913</td>\n",
       "      <td>0.322750</td>\n",
       "      <td>-0.363102</td>\n",
       "      <td>0.098256</td>\n",
       "      <td>-0.759535</td>\n",
       "      <td>-0.244696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>-0.284253</td>\n",
       "      <td>-0.756383</td>\n",
       "      <td>0.784185</td>\n",
       "      <td>0.245781</td>\n",
       "      <td>-0.217883</td>\n",
       "      <td>-0.411314</td>\n",
       "      <td>0.006313</td>\n",
       "      <td>-0.081967</td>\n",
       "      <td>-0.082813</td>\n",
       "      <td>-1.140420</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.822037</td>\n",
       "      <td>0.241155</td>\n",
       "      <td>-0.176131</td>\n",
       "      <td>-0.117470</td>\n",
       "      <td>0.494665</td>\n",
       "      <td>0.277910</td>\n",
       "      <td>-0.839016</td>\n",
       "      <td>-0.212997</td>\n",
       "      <td>-0.053063</td>\n",
       "      <td>-1.011198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>0.066911</td>\n",
       "      <td>0.108697</td>\n",
       "      <td>0.117314</td>\n",
       "      <td>-0.026495</td>\n",
       "      <td>0.015199</td>\n",
       "      <td>0.079509</td>\n",
       "      <td>-0.211216</td>\n",
       "      <td>0.084738</td>\n",
       "      <td>-0.009791</td>\n",
       "      <td>0.068621</td>\n",
       "      <td>...</td>\n",
       "      <td>0.129855</td>\n",
       "      <td>-0.015207</td>\n",
       "      <td>-0.077254</td>\n",
       "      <td>-0.055104</td>\n",
       "      <td>-0.080412</td>\n",
       "      <td>0.157144</td>\n",
       "      <td>0.227705</td>\n",
       "      <td>-0.226615</td>\n",
       "      <td>-0.020310</td>\n",
       "      <td>0.101783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>automated''</th>\n",
       "      <td>0.034742</td>\n",
       "      <td>0.024435</td>\n",
       "      <td>-0.035676</td>\n",
       "      <td>-0.049706</td>\n",
       "      <td>0.029638</td>\n",
       "      <td>0.022952</td>\n",
       "      <td>0.011129</td>\n",
       "      <td>-0.154946</td>\n",
       "      <td>-0.134221</td>\n",
       "      <td>0.064848</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025236</td>\n",
       "      <td>-0.079394</td>\n",
       "      <td>0.159307</td>\n",
       "      <td>0.042786</td>\n",
       "      <td>-0.130191</td>\n",
       "      <td>0.089049</td>\n",
       "      <td>-0.016407</td>\n",
       "      <td>-0.054820</td>\n",
       "      <td>0.087518</td>\n",
       "      <td>0.114606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>0.033926</td>\n",
       "      <td>0.170894</td>\n",
       "      <td>0.087645</td>\n",
       "      <td>-0.031428</td>\n",
       "      <td>-0.038994</td>\n",
       "      <td>0.038913</td>\n",
       "      <td>-0.184922</td>\n",
       "      <td>0.008812</td>\n",
       "      <td>-0.069440</td>\n",
       "      <td>0.067128</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128920</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>-0.017345</td>\n",
       "      <td>-0.083919</td>\n",
       "      <td>-0.037820</td>\n",
       "      <td>0.150396</td>\n",
       "      <td>0.248054</td>\n",
       "      <td>-0.204338</td>\n",
       "      <td>-0.037215</td>\n",
       "      <td>0.093046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>screenings</th>\n",
       "      <td>0.195423</td>\n",
       "      <td>0.028148</td>\n",
       "      <td>0.039086</td>\n",
       "      <td>-0.015086</td>\n",
       "      <td>-0.050388</td>\n",
       "      <td>0.027777</td>\n",
       "      <td>-0.067449</td>\n",
       "      <td>0.064195</td>\n",
       "      <td>-0.061795</td>\n",
       "      <td>-0.068845</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050059</td>\n",
       "      <td>0.038295</td>\n",
       "      <td>0.016049</td>\n",
       "      <td>0.132378</td>\n",
       "      <td>0.034546</td>\n",
       "      <td>0.030001</td>\n",
       "      <td>0.030840</td>\n",
       "      <td>-0.048373</td>\n",
       "      <td>0.060404</td>\n",
       "      <td>0.080170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2464</th>\n",
       "      <td>-0.007101</td>\n",
       "      <td>-0.059626</td>\n",
       "      <td>0.101549</td>\n",
       "      <td>-0.059232</td>\n",
       "      <td>0.012252</td>\n",
       "      <td>-0.152667</td>\n",
       "      <td>-0.161547</td>\n",
       "      <td>0.052095</td>\n",
       "      <td>0.069299</td>\n",
       "      <td>-0.159803</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024469</td>\n",
       "      <td>0.238262</td>\n",
       "      <td>-0.022484</td>\n",
       "      <td>-0.059594</td>\n",
       "      <td>0.120288</td>\n",
       "      <td>0.039246</td>\n",
       "      <td>0.071109</td>\n",
       "      <td>0.152648</td>\n",
       "      <td>0.071906</td>\n",
       "      <td>-0.163807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12134 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    1         2         3         4         5         6  \\\n",
       "<start>     -0.251972 -0.335857  0.743956  0.287609 -0.320067 -0.336197   \n",
       "to          -0.095761 -0.244435  0.169767 -0.254720  0.520574  0.380848   \n",
       "the         -0.040541 -1.178647  0.772364  0.711954  0.177214 -0.639962   \n",
       "i           -0.406263  0.581536  0.150963  0.089914 -0.085831 -0.187691   \n",
       "a           -0.284253 -0.756383  0.784185  0.245781 -0.217883 -0.411314   \n",
       "...               ...       ...       ...       ...       ...       ...   \n",
       "1147         0.066911  0.108697  0.117314 -0.026495  0.015199  0.079509   \n",
       "automated''  0.034742  0.024435 -0.035676 -0.049706  0.029638  0.022952   \n",
       "930          0.033926  0.170894  0.087645 -0.031428 -0.038994  0.038913   \n",
       "screenings   0.195423  0.028148  0.039086 -0.015086 -0.050388  0.027777   \n",
       "2464        -0.007101 -0.059626  0.101549 -0.059232  0.012252 -0.152667   \n",
       "\n",
       "                    7         8         9        10  ...       759       760  \\\n",
       "<start>      0.651577 -0.417630  0.072657  0.669512  ...  0.118542  0.013129   \n",
       "to          -0.152164  0.410601  0.975136  0.334161  ... -0.455171 -0.563830   \n",
       "the         -0.159563  0.261875  0.473067 -0.223687  ... -0.444203 -0.343703   \n",
       "i           -0.108174  0.237551  0.576532  0.273172  ... -0.107218 -0.156319   \n",
       "a            0.006313 -0.081967 -0.082813 -1.140420  ... -0.822037  0.241155   \n",
       "...               ...       ...       ...       ...  ...       ...       ...   \n",
       "1147        -0.211216  0.084738 -0.009791  0.068621  ...  0.129855 -0.015207   \n",
       "automated''  0.011129 -0.154946 -0.134221  0.064848  ... -0.025236 -0.079394   \n",
       "930         -0.184922  0.008812 -0.069440  0.067128  ...  0.128920 -0.038195   \n",
       "screenings  -0.067449  0.064195 -0.061795 -0.068845  ... -0.050059  0.038295   \n",
       "2464        -0.161547  0.052095  0.069299 -0.159803  ... -0.024469  0.238262   \n",
       "\n",
       "                  761       762       763       764       765       766  \\\n",
       "<start>     -0.103702  0.214072  0.223253  0.165746 -0.625366 -0.433057   \n",
       "to           0.425149 -0.744738  0.315320 -1.070223 -0.815350  0.106142   \n",
       "the         -0.317150 -0.642309  1.033737  0.581608  0.067017 -0.575224   \n",
       "i           -0.019238 -0.439631 -0.072913  0.322750 -0.363102  0.098256   \n",
       "a           -0.176131 -0.117470  0.494665  0.277910 -0.839016 -0.212997   \n",
       "...               ...       ...       ...       ...       ...       ...   \n",
       "1147        -0.077254 -0.055104 -0.080412  0.157144  0.227705 -0.226615   \n",
       "automated''  0.159307  0.042786 -0.130191  0.089049 -0.016407 -0.054820   \n",
       "930         -0.017345 -0.083919 -0.037820  0.150396  0.248054 -0.204338   \n",
       "screenings   0.016049  0.132378  0.034546  0.030001  0.030840 -0.048373   \n",
       "2464        -0.022484 -0.059594  0.120288  0.039246  0.071109  0.152648   \n",
       "\n",
       "                  767       768  \n",
       "<start>     -0.647071 -0.493110  \n",
       "to           0.148487 -0.391389  \n",
       "the          0.700265 -0.863741  \n",
       "i           -0.759535 -0.244696  \n",
       "a           -0.053063 -1.011198  \n",
       "...               ...       ...  \n",
       "1147        -0.020310  0.101783  \n",
       "automated''  0.087518  0.114606  \n",
       "930         -0.037215  0.093046  \n",
       "screenings   0.060404  0.080170  \n",
       "2464         0.071906 -0.163807  \n",
       "\n",
       "[12134 rows x 768 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12136"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_index = list(embedding_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12134"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(emb_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = []\n",
    "for word in list(word_index.keys()) :\n",
    "    if not word in emb_index :\n",
    "        outliers.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = []\n",
    "word_index_keys = list(word_index.keys())\n",
    "for word in emb_index :\n",
    "    if not word in word_index_keys :\n",
    "        outliers.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13176 (13176, 256) (13176, 256) (13176, 3)\n",
      "<start> iad to jfk still has n't boarded what's today's excuse and how am i gon na get to work <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> [1 0 0]\n",
      "1464 (1464, 256) (1464, 256) (1464, 3)\n",
      "<start> was in a line a mile long at sky harbor this morning your staff was courteous and <unk> thank you <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> [0 0 1]\n"
     ]
    }
   ],
   "source": [
    "i_fold = 3\n",
    "\n",
    "embeddings_df = embeddings_dfs[i_fold]\n",
    "\n",
    "train_dataframe = pd.concat(folds_dfs[ : i_fold] + folds_dfs[i_fold + 1 : ])\n",
    "valid_dataframe = folds_dfs[i_fold]\n",
    "\n",
    "word_index, decode_review = get_word_index(train_dataframe[\"text\"])\n",
    "if experiment[\"args\"][\"vocab_size\"] is None :\n",
    "    experiment[\"args\"][\"vocab_size\"] = len(word_index)\n",
    "\n",
    "ids_train, x_train, mask_train, y_train = get_dataset(train_dataframe, word_index, n_classes=experiment[\"args\"][\"n_classes\"])\n",
    "print(len(ids_train), x_train.shape, mask_train.shape, y_train.shape)\n",
    "print(decode_review(x_train[1]), y_train[1])\n",
    "\n",
    "ids_valid, x_valid, mask_valid, y_valid = get_dataset(valid_dataframe, word_index, n_classes=experiment[\"args\"][\"n_classes\"])\n",
    "print(len(ids_valid), x_valid.shape, mask_valid.shape, y_valid.shape)\n",
    "print(decode_review(x_valid[1]), y_valid[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "      <th>768</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;start&gt;</th>\n",
       "      <td>-0.282846</td>\n",
       "      <td>-0.485796</td>\n",
       "      <td>-0.038414</td>\n",
       "      <td>0.352181</td>\n",
       "      <td>-0.564837</td>\n",
       "      <td>0.169060</td>\n",
       "      <td>0.218938</td>\n",
       "      <td>0.147674</td>\n",
       "      <td>0.519879</td>\n",
       "      <td>0.071983</td>\n",
       "      <td>...</td>\n",
       "      <td>0.788335</td>\n",
       "      <td>0.355169</td>\n",
       "      <td>-0.353737</td>\n",
       "      <td>-0.654546</td>\n",
       "      <td>-0.739606</td>\n",
       "      <td>0.774340</td>\n",
       "      <td>0.977387</td>\n",
       "      <td>-0.108453</td>\n",
       "      <td>-0.701812</td>\n",
       "      <td>1.476708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>-0.415130</td>\n",
       "      <td>-1.033926</td>\n",
       "      <td>0.068353</td>\n",
       "      <td>0.440023</td>\n",
       "      <td>-0.405840</td>\n",
       "      <td>0.913767</td>\n",
       "      <td>-0.697176</td>\n",
       "      <td>-0.593707</td>\n",
       "      <td>0.068347</td>\n",
       "      <td>-0.544617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463278</td>\n",
       "      <td>-0.190466</td>\n",
       "      <td>-0.006372</td>\n",
       "      <td>-1.845080</td>\n",
       "      <td>-1.871068</td>\n",
       "      <td>0.187292</td>\n",
       "      <td>1.300340</td>\n",
       "      <td>-0.927931</td>\n",
       "      <td>-0.190056</td>\n",
       "      <td>1.390106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>0.642369</td>\n",
       "      <td>-0.869593</td>\n",
       "      <td>0.740655</td>\n",
       "      <td>0.698861</td>\n",
       "      <td>-0.100020</td>\n",
       "      <td>-0.076253</td>\n",
       "      <td>-0.532491</td>\n",
       "      <td>0.089165</td>\n",
       "      <td>0.047654</td>\n",
       "      <td>0.244985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.431776</td>\n",
       "      <td>-0.542156</td>\n",
       "      <td>-0.986821</td>\n",
       "      <td>-1.289415</td>\n",
       "      <td>-0.163144</td>\n",
       "      <td>1.409486</td>\n",
       "      <td>0.956747</td>\n",
       "      <td>-0.454120</td>\n",
       "      <td>-0.163223</td>\n",
       "      <td>0.987065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>0.158433</td>\n",
       "      <td>-0.469385</td>\n",
       "      <td>-0.073635</td>\n",
       "      <td>-0.132904</td>\n",
       "      <td>-0.902013</td>\n",
       "      <td>0.510985</td>\n",
       "      <td>-0.734310</td>\n",
       "      <td>0.219299</td>\n",
       "      <td>0.671551</td>\n",
       "      <td>-0.015053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.668103</td>\n",
       "      <td>0.064029</td>\n",
       "      <td>-0.218738</td>\n",
       "      <td>-1.440547</td>\n",
       "      <td>-1.043749</td>\n",
       "      <td>0.685961</td>\n",
       "      <td>1.527858</td>\n",
       "      <td>-0.738634</td>\n",
       "      <td>-1.085329</td>\n",
       "      <td>1.415565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>-0.111537</td>\n",
       "      <td>-0.689202</td>\n",
       "      <td>0.877903</td>\n",
       "      <td>-0.269690</td>\n",
       "      <td>0.183240</td>\n",
       "      <td>0.115914</td>\n",
       "      <td>-0.101982</td>\n",
       "      <td>0.018584</td>\n",
       "      <td>-0.157449</td>\n",
       "      <td>-0.158345</td>\n",
       "      <td>...</td>\n",
       "      <td>1.076107</td>\n",
       "      <td>-0.535732</td>\n",
       "      <td>-0.057149</td>\n",
       "      <td>-1.205376</td>\n",
       "      <td>-1.086794</td>\n",
       "      <td>1.163292</td>\n",
       "      <td>1.485147</td>\n",
       "      <td>-1.402447</td>\n",
       "      <td>0.400378</td>\n",
       "      <td>0.712581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>renewed</th>\n",
       "      <td>0.074851</td>\n",
       "      <td>-0.038765</td>\n",
       "      <td>-0.051553</td>\n",
       "      <td>0.026132</td>\n",
       "      <td>0.056374</td>\n",
       "      <td>-0.123528</td>\n",
       "      <td>-0.042322</td>\n",
       "      <td>0.163471</td>\n",
       "      <td>-0.216049</td>\n",
       "      <td>-0.074544</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050555</td>\n",
       "      <td>0.096236</td>\n",
       "      <td>-0.121695</td>\n",
       "      <td>-0.147618</td>\n",
       "      <td>-0.042536</td>\n",
       "      <td>0.047722</td>\n",
       "      <td>0.096364</td>\n",
       "      <td>0.018134</td>\n",
       "      <td>0.059003</td>\n",
       "      <td>-0.029817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ua761</th>\n",
       "      <td>0.030084</td>\n",
       "      <td>-0.010749</td>\n",
       "      <td>-0.053900</td>\n",
       "      <td>-0.006302</td>\n",
       "      <td>0.080238</td>\n",
       "      <td>0.077685</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>0.058809</td>\n",
       "      <td>0.109591</td>\n",
       "      <td>0.121032</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053510</td>\n",
       "      <td>-0.164922</td>\n",
       "      <td>0.125757</td>\n",
       "      <td>0.041468</td>\n",
       "      <td>-0.036388</td>\n",
       "      <td>0.021465</td>\n",
       "      <td>0.004651</td>\n",
       "      <td>-0.082069</td>\n",
       "      <td>0.001113</td>\n",
       "      <td>0.006983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moves</th>\n",
       "      <td>0.022142</td>\n",
       "      <td>-0.021479</td>\n",
       "      <td>0.128811</td>\n",
       "      <td>-0.018625</td>\n",
       "      <td>0.078715</td>\n",
       "      <td>-0.000661</td>\n",
       "      <td>-0.105004</td>\n",
       "      <td>0.058264</td>\n",
       "      <td>-0.063435</td>\n",
       "      <td>-0.002328</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061755</td>\n",
       "      <td>0.070977</td>\n",
       "      <td>-0.020302</td>\n",
       "      <td>-0.048003</td>\n",
       "      <td>0.011098</td>\n",
       "      <td>0.005438</td>\n",
       "      <td>0.081405</td>\n",
       "      <td>-0.020868</td>\n",
       "      <td>-0.023329</td>\n",
       "      <td>0.039025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clockwork</th>\n",
       "      <td>-0.112291</td>\n",
       "      <td>-0.067761</td>\n",
       "      <td>-0.064172</td>\n",
       "      <td>0.096315</td>\n",
       "      <td>0.094721</td>\n",
       "      <td>-0.001640</td>\n",
       "      <td>0.099411</td>\n",
       "      <td>-0.083651</td>\n",
       "      <td>0.160123</td>\n",
       "      <td>-0.050896</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037912</td>\n",
       "      <td>-0.173050</td>\n",
       "      <td>-0.009925</td>\n",
       "      <td>-0.069573</td>\n",
       "      <td>-0.144182</td>\n",
       "      <td>0.300522</td>\n",
       "      <td>0.064133</td>\n",
       "      <td>-0.018481</td>\n",
       "      <td>-0.056886</td>\n",
       "      <td>0.087694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ctg</th>\n",
       "      <td>0.032709</td>\n",
       "      <td>-0.091708</td>\n",
       "      <td>0.086493</td>\n",
       "      <td>0.038489</td>\n",
       "      <td>-0.020235</td>\n",
       "      <td>-0.088093</td>\n",
       "      <td>-0.033689</td>\n",
       "      <td>-0.110713</td>\n",
       "      <td>-0.031637</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014714</td>\n",
       "      <td>0.193294</td>\n",
       "      <td>-0.040438</td>\n",
       "      <td>-0.235827</td>\n",
       "      <td>-0.036547</td>\n",
       "      <td>0.088389</td>\n",
       "      <td>0.014299</td>\n",
       "      <td>-0.064934</td>\n",
       "      <td>0.059912</td>\n",
       "      <td>-0.005553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12127 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  1         2         3         4         5         6  \\\n",
       "<start>   -0.282846 -0.485796 -0.038414  0.352181 -0.564837  0.169060   \n",
       "to        -0.415130 -1.033926  0.068353  0.440023 -0.405840  0.913767   \n",
       "the        0.642369 -0.869593  0.740655  0.698861 -0.100020 -0.076253   \n",
       "i          0.158433 -0.469385 -0.073635 -0.132904 -0.902013  0.510985   \n",
       "a         -0.111537 -0.689202  0.877903 -0.269690  0.183240  0.115914   \n",
       "...             ...       ...       ...       ...       ...       ...   \n",
       "renewed    0.074851 -0.038765 -0.051553  0.026132  0.056374 -0.123528   \n",
       "ua761      0.030084 -0.010749 -0.053900 -0.006302  0.080238  0.077685   \n",
       "moves      0.022142 -0.021479  0.128811 -0.018625  0.078715 -0.000661   \n",
       "clockwork -0.112291 -0.067761 -0.064172  0.096315  0.094721 -0.001640   \n",
       "ctg        0.032709 -0.091708  0.086493  0.038489 -0.020235 -0.088093   \n",
       "\n",
       "                  7         8         9        10  ...       759       760  \\\n",
       "<start>    0.218938  0.147674  0.519879  0.071983  ...  0.788335  0.355169   \n",
       "to        -0.697176 -0.593707  0.068347 -0.544617  ...  0.463278 -0.190466   \n",
       "the       -0.532491  0.089165  0.047654  0.244985  ...  0.431776 -0.542156   \n",
       "i         -0.734310  0.219299  0.671551 -0.015053  ...  0.668103  0.064029   \n",
       "a         -0.101982  0.018584 -0.157449 -0.158345  ...  1.076107 -0.535732   \n",
       "...             ...       ...       ...       ...  ...       ...       ...   \n",
       "renewed   -0.042322  0.163471 -0.216049 -0.074544  ...  0.050555  0.096236   \n",
       "ua761      0.000377  0.058809  0.109591  0.121032  ... -0.053510 -0.164922   \n",
       "moves     -0.105004  0.058264 -0.063435 -0.002328  ...  0.061755  0.070977   \n",
       "clockwork  0.099411 -0.083651  0.160123 -0.050896  ... -0.037912 -0.173050   \n",
       "ctg       -0.033689 -0.110713 -0.031637  0.000049  ...  0.014714  0.193294   \n",
       "\n",
       "                761       762       763       764       765       766  \\\n",
       "<start>   -0.353737 -0.654546 -0.739606  0.774340  0.977387 -0.108453   \n",
       "to        -0.006372 -1.845080 -1.871068  0.187292  1.300340 -0.927931   \n",
       "the       -0.986821 -1.289415 -0.163144  1.409486  0.956747 -0.454120   \n",
       "i         -0.218738 -1.440547 -1.043749  0.685961  1.527858 -0.738634   \n",
       "a         -0.057149 -1.205376 -1.086794  1.163292  1.485147 -1.402447   \n",
       "...             ...       ...       ...       ...       ...       ...   \n",
       "renewed   -0.121695 -0.147618 -0.042536  0.047722  0.096364  0.018134   \n",
       "ua761      0.125757  0.041468 -0.036388  0.021465  0.004651 -0.082069   \n",
       "moves     -0.020302 -0.048003  0.011098  0.005438  0.081405 -0.020868   \n",
       "clockwork -0.009925 -0.069573 -0.144182  0.300522  0.064133 -0.018481   \n",
       "ctg       -0.040438 -0.235827 -0.036547  0.088389  0.014299 -0.064934   \n",
       "\n",
       "                767       768  \n",
       "<start>   -0.701812  1.476708  \n",
       "to        -0.190056  1.390106  \n",
       "the       -0.163223  0.987065  \n",
       "i         -1.085329  1.415565  \n",
       "a          0.400378  0.712581  \n",
       "...             ...       ...  \n",
       "renewed    0.059003 -0.029817  \n",
       "ua761      0.001113  0.006983  \n",
       "moves     -0.023329  0.039025  \n",
       "clockwork -0.056886  0.087694  \n",
       "ctg        0.059912 -0.005553  \n",
       "\n",
       "[12127 rows x 768 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12129"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb071969cc081d156db4658a52cc12ff3302089485c0c8cb524fcf02c6362775"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
